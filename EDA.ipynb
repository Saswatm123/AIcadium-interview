{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Administrative</th>\n",
       "      <th>Administrative_Duration</th>\n",
       "      <th>Informational</th>\n",
       "      <th>Informational_Duration</th>\n",
       "      <th>ProductRelated</th>\n",
       "      <th>ProductRelated_Duration</th>\n",
       "      <th>BounceRates</th>\n",
       "      <th>ExitRates</th>\n",
       "      <th>PageValues</th>\n",
       "      <th>SpecialDay</th>\n",
       "      <th>Month</th>\n",
       "      <th>OperatingSystems</th>\n",
       "      <th>Browser</th>\n",
       "      <th>Region</th>\n",
       "      <th>TrafficType</th>\n",
       "      <th>VisitorType</th>\n",
       "      <th>Weekend</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>627.500000</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Administrative  Administrative_Duration  Informational  \\\n",
       "0               0                      0.0              0   \n",
       "1               0                      0.0              0   \n",
       "2               0                      0.0              0   \n",
       "3               0                      0.0              0   \n",
       "4               0                      0.0              0   \n",
       "\n",
       "   Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
       "0                     0.0               1                 0.000000   \n",
       "1                     0.0               2                64.000000   \n",
       "2                     0.0               1                 0.000000   \n",
       "3                     0.0               2                 2.666667   \n",
       "4                     0.0              10               627.500000   \n",
       "\n",
       "   BounceRates  ExitRates  PageValues  SpecialDay Month  OperatingSystems  \\\n",
       "0         0.20       0.20         0.0         0.0   Feb                 1   \n",
       "1         0.00       0.10         0.0         0.0   Feb                 2   \n",
       "2         0.20       0.20         0.0         0.0   Feb                 4   \n",
       "3         0.05       0.14         0.0         0.0   Feb                 3   \n",
       "4         0.02       0.05         0.0         0.0   Feb                 3   \n",
       "\n",
       "   Browser  Region  TrafficType        VisitorType  Weekend  Revenue  \n",
       "0        1       1            1  Returning_Visitor    False    False  \n",
       "1        2       1            2  Returning_Visitor    False    False  \n",
       "2        1       9            3  Returning_Visitor    False    False  \n",
       "3        2       2            4  Returning_Visitor    False    False  \n",
       "4        3       1            4  Returning_Visitor     True    False  "
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('coding_round_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15474452554744525"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the proportion of positive class labels\n",
    "data['Revenue'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "SEED = 12345 # To ensure we don't leak data between RAM resets (like shutting off my computer)\n",
    "splitter = StratifiedShuffleSplit(n_splits = 1, test_size = .2, random_state = SEED)\n",
    "train, test = list( splitter.split(X = data, y = data['Revenue']) )[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To make sure the proportions of positive class labels in train, test are the same\n",
    "np.isclose(data.iloc[test,:]['Revenue'].mean(), data.iloc[train,:]['Revenue'].mean(), atol = .001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.iloc[train,:]\n",
    "test_data = data.iloc[test,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "May     2675\n",
       "Nov     2407\n",
       "Mar     1532\n",
       "Dec     1365\n",
       "Oct      439\n",
       "Jul      361\n",
       "Sep      350\n",
       "Aug      342\n",
       "June     241\n",
       "Feb      152\n",
       "Name: Month, dtype: int64"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Month'].value_counts()\n",
    "# Looks like there are only 10 months reported. We will start by encoding the months variable so that \n",
    "# the months are circular, and our feature will include information that December is closer to January\n",
    "# than June. We can make it circular by replacing the Month value with the cosine & sine of the month's\n",
    "# proportional distance between 0 and 2pi (ex. Jan=0=2pi, Dec=11pi/6=2pi-pi/12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pipeline:\n",
    "    def __init__(self, *funcs):\n",
    "        '''\n",
    "            Desc:\n",
    "                Takes in a list of functions & applies them to any pd.DataFramem passed\n",
    "                in through the __call__ method.\n",
    "            Args:\n",
    "                *funcs: A list of functions\n",
    "        '''\n",
    "        self.funcs = list([func.__name__, func] for func in funcs)\n",
    "    \n",
    "    def __call__(self, dataframe):\n",
    "        for funcname, func in self.funcs:\n",
    "            print(\"Applying func\", funcname)\n",
    "            dataframe = func(dataframe)\n",
    "        return dataframe\n",
    "    \n",
    "    def add(self, func):\n",
    "        self.funcs.append( (func.__name__, func) )\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"Pipeline: \" + ', '.join(funcname for funcname, _ in self.funcs)\n",
    "\n",
    "pipeline = Pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_months_circular(df):\n",
    "    months_map = dict(\n",
    "        zip(\n",
    "            ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'June', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'],\n",
    "            np.linspace(0,2*np.pi-2*np.pi/12,12)\n",
    "        )\n",
    "    )\n",
    "    months_radian = df['Month'].apply(lambda month : months_map[month])\n",
    "    months_x, months_y = np.cos(months_radian), np.sin(months_radian)\n",
    "    df_updated = df.drop('Month', axis=1)\n",
    "    df_updated['Month_x'] = months_x\n",
    "    df_updated['Month_y'] = months_y\n",
    "    return df_updated\n",
    "train_data = make_months_circular(train_data)\n",
    "pipeline.add(make_months_circular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Administrative               int64\n",
       "Administrative_Duration    float64\n",
       "Informational                int64\n",
       "Informational_Duration     float64\n",
       "ProductRelated               int64\n",
       "ProductRelated_Duration    float64\n",
       "BounceRates                float64\n",
       "ExitRates                  float64\n",
       "PageValues                 float64\n",
       "SpecialDay                 float64\n",
       "OperatingSystems             int64\n",
       "Browser                      int64\n",
       "Region                       int64\n",
       "TrafficType                  int64\n",
       "VisitorType                 object\n",
       "Weekend                       bool\n",
       "Revenue                       bool\n",
       "Month_x                    float64\n",
       "Month_y                    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We now check the data types to see if any types need changing (int -> categorical, etc)\n",
    "train_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see that some of the data types still need some changing. (1, 2) as integers are different \n",
    "# from (1, 2) as categories (unordered).\n",
    "\n",
    "def make_data_categorical(df):\n",
    "    df[['OperatingSystems', 'Browser', 'Region', 'TrafficType', 'VisitorType']] = df[['OperatingSystems', 'Browser', 'Region', 'TrafficType', 'VisitorType']].astype('category')\n",
    "    return df\n",
    "\n",
    "make_data_categorical(train_data)\n",
    "pipeline.add(make_data_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Administrative                int64\n",
       "Administrative_Duration     float64\n",
       "Informational                 int64\n",
       "Informational_Duration      float64\n",
       "ProductRelated                int64\n",
       "ProductRelated_Duration     float64\n",
       "BounceRates                 float64\n",
       "ExitRates                   float64\n",
       "PageValues                  float64\n",
       "SpecialDay                  float64\n",
       "OperatingSystems           category\n",
       "Browser                    category\n",
       "Region                     category\n",
       "TrafficType                category\n",
       "VisitorType                category\n",
       "Weekend                        bool\n",
       "Revenue                        bool\n",
       "Month_x                     float64\n",
       "Month_y                     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.dtypes\n",
    "\n",
    "# We can see now that the data types for the wrongly int-casted data types are fixed as categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now I will do some final checking up on some of the other features of interest.\n",
    "train_data['SpecialDay'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    8868\n",
       "0.6     274\n",
       "0.8     252\n",
       "0.4     200\n",
       "0.2     140\n",
       "1.0     130\n",
       "Name: SpecialDay, dtype: int64"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['SpecialDay'].value_counts()\n",
    "# Since SpecialDay has a fixed number of values, we will look at proportions of buys given the date falls\n",
    "# on a day with the given SpecialDay value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpecialDay\n",
       "0.0    0.164975\n",
       "0.2    0.064286\n",
       "0.4    0.055000\n",
       "0.6    0.087591\n",
       "0.8    0.039683\n",
       "1.0    0.069231\n",
       "Name: Revenue, dtype: float64"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.groupby(['SpecialDay'])['Revenue'].mean()\n",
    "# It initially seems like the proportion of buys given proximity to a special date goes down \n",
    "# compared to not having a special day coming up. There is a Region variable. We can test if these \n",
    "# \"Special Days\" are special in only some regions (ie. Diwali or Chinese New Year may not be as \n",
    "# special/popular in America as they are in their respective regions of origin.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Region  SpecialDay\n",
       "1       0.0           0.178198\n",
       "        0.2           0.017241\n",
       "        0.4           0.028169\n",
       "        0.6           0.076271\n",
       "        0.8           0.009804\n",
       "        1.0           0.125000\n",
       "2       0.0           0.172414\n",
       "        0.2           0.125000\n",
       "        0.4           0.142857\n",
       "        0.6           0.238095\n",
       "        0.8           0.071429\n",
       "        1.0           0.071429\n",
       "3       0.0           0.157522\n",
       "        0.2           0.032258\n",
       "        0.4           0.000000\n",
       "        0.6           0.033898\n",
       "        0.8           0.108696\n",
       "        1.0           0.030303\n",
       "4       0.0           0.154299\n",
       "        0.2           0.083333\n",
       "        0.4           0.000000\n",
       "        0.6           0.208333\n",
       "        0.8           0.000000\n",
       "        1.0           0.000000\n",
       "5       0.0           0.152466\n",
       "        0.2           0.000000\n",
       "        0.4           0.142857\n",
       "        0.6           0.000000\n",
       "        0.8           0.000000\n",
       "        1.0           0.000000\n",
       "6       0.0           0.136752\n",
       "        0.2           0.100000\n",
       "        0.4           0.066667\n",
       "        0.6           0.000000\n",
       "        0.8           0.000000\n",
       "        1.0           0.000000\n",
       "7       0.0           0.176471\n",
       "        0.2           0.000000\n",
       "        0.4           0.000000\n",
       "        0.6           0.142857\n",
       "        0.8           0.000000\n",
       "        1.0           0.058824\n",
       "8       0.0           0.122642\n",
       "        0.2           0.500000\n",
       "        0.4           0.285714\n",
       "        0.6           0.000000\n",
       "        0.8           0.111111\n",
       "        1.0           0.000000\n",
       "9       0.0           0.155844\n",
       "        0.2           1.000000\n",
       "        0.4           0.000000\n",
       "        0.6           0.125000\n",
       "        0.8           0.166667\n",
       "        1.0           0.250000\n",
       "Name: Revenue, dtype: float64"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.groupby(['Region', 'SpecialDay'])['Revenue'].mean()\n",
    "# It looks like we get mixed results for whether a region considers a day \"Special\". Without knowing\n",
    "# the actual special days (knowing whether the day is halloween, Chinese New Year, etc.) and regions,\n",
    "# it will likely be better to just leave as is and use regularization down the line. Another problem\n",
    "# is that as we group by more variables, we get smaller sample sizes, so I want to avoid being\n",
    "# overconfident at this level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying func make_months_circular\n",
      "Applying func make_data_categorical\n"
     ]
    }
   ],
   "source": [
    "test_data = pipeline(test_data)\n",
    "# This cell just checks if the pipeline class works, which it does. We will now move to model selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = train_data[['VisitorType']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "c['new'] = c['VisitorType'].cat.codes.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "c['new2'] = c['VisitorType'].apply(lambda row : cat_to_codes[row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(c['new'].dtype, pd.CategoricalDtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes_to_cat = dict( list(enumerate(c['VisitorType'].cat.categories ) ) )\n",
    "cat_to_codes = dict( ( (value, key) for key, value in codes_to_cat.items() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load, dump\n",
    "def nonnumeric_to_categorical_numeric(df):\n",
    "    conversions = []\n",
    "    def convert(col):\n",
    "        nonlocal conversions\n",
    "        if isinstance(col.dtype, pd.CategoricalDtype):\n",
    "            codes_to_cat = dict( list(enumerate(col.cat.categories ) ) )\n",
    "            cat_to_codes = dict( ( (value, key) for key, value in codes_to_cat.items() ) )\n",
    "            conversions.append( {\n",
    "                'name' : col.name, \n",
    "                'codes_to_cat' : codes_to_cat, \n",
    "                'cat_to_codes' : cat_to_codes\n",
    "            })\n",
    "            col = col.apply(lambda row : cat_to_codes[row])\n",
    "        return col\n",
    "    updated_df = df.apply(convert, axis=0)\n",
    "    dump(updated_df, './metadata/conversions.final')\n",
    "    return updated_df\n",
    "        \n",
    "train_data = nonnumeric_to_categorical_numeric(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Experimental support for categorical data is not implemented for current tree method yet.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-404-071d8a46cda3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m  \u001b[0menable_categorical\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_label_encoder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m )\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Revenue'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Revenue'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\ML\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    504\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 506\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1228\u001b[0m             \u001b[0mlabel_transform\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1230\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_configure_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1231\u001b[0m         train_dmatrix, evals = _wrap_evaluation_matrices(\n\u001b[0;32m   1232\u001b[0m             \u001b[0mmissing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36m_configure_fit\u001b[1;34m(self, booster, eval_metric, params)\u001b[0m\n\u001b[0;32m    652\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"eval_metric\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_categorical\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tree_method\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"gpu_hist\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 654\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    655\u001b[0m                 \u001b[1;34m\"Experimental support for categorical data is not implemented for\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    656\u001b[0m                 \u001b[1;34m\" current tree method yet.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Experimental support for categorical data is not implemented for current tree method yet."
     ]
    }
   ],
   "source": [
    "clf = XGBClassifier( tree_method = 'hist',\n",
    " enable_categorical=True, use_label_encoder=False\n",
    ")\n",
    "clf.fit(train_data.drop('Revenue', axis=1), train_data['Revenue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Experimental support for categorical data is not implemented for current tree method yet.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-400-a2855f2a3973>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mreg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXGBRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menable_categorical\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Revenue'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Revenue'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\ML\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    504\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 506\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m    786\u001b[0m             \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    787\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 788\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_configure_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    789\u001b[0m         self._Booster = train(\n\u001b[0;32m    790\u001b[0m             \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36m_configure_fit\u001b[1;34m(self, booster, eval_metric, params)\u001b[0m\n\u001b[0;32m    652\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"eval_metric\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_categorical\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tree_method\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"gpu_hist\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 654\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    655\u001b[0m                 \u001b[1;34m\"Experimental support for categorical data is not implemented for\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    656\u001b[0m                 \u001b[1;34m\" current tree method yet.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Experimental support for categorical data is not implemented for current tree method yet."
     ]
    }
   ],
   "source": [
    "reg = XGBRegressor(enable_categorical=True)\n",
    "reg.fit(train_data.drop('Revenue', axis=1), train_data['Revenue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "from xgboost import XGBClassifier, XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv = GridSearchCV(\n",
    "    estimator = XGBRegressor(n_jobs = -1, objective = 'reg:squarederror', enable_categorical=True),\n",
    "    param_grid = {\n",
    "        'max_depth'     : [3,4],\n",
    "        'learning_rate' : [.001, .01],\n",
    "        'n_estimators'  : [200,300,400]\n",
    "    },\n",
    "    scoring = make_scorer(roc_auc_score),\n",
    "    n_jobs = -1,\n",
    "    verbose = 10,\n",
    "    cv = 7,\n",
    "    return_train_score = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 12 candidates, totalling 84 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0628s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1985s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  84 out of  84 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Experimental support for categorical data is not implemented for current tree method yet.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-297-6e11da99210e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgscv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Revenue'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Revenue'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\ML\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    763\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    504\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 506\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m    786\u001b[0m             \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    787\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 788\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_configure_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    789\u001b[0m         self._Booster = train(\n\u001b[0;32m    790\u001b[0m             \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36m_configure_fit\u001b[1;34m(self, booster, eval_metric, params)\u001b[0m\n\u001b[0;32m    652\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"eval_metric\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_categorical\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tree_method\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"gpu_hist\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 654\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    655\u001b[0m                 \u001b[1;34m\"Experimental support for categorical data is not implemented for\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    656\u001b[0m                 \u001b[1;34m\" current tree method yet.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Experimental support for categorical data is not implemented for current tree method yet."
     ]
    }
   ],
   "source": [
    "gscv.fit(train_data.drop('Revenue', axis=1), train_data['Revenue'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
